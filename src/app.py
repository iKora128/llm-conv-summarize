"""
LLMåŒå£«ã®ãƒãƒ£ãƒƒãƒˆå®Ÿé¨“ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""
import os
import json
import time
from datetime import datetime
import streamlit as st
from dotenv import load_dotenv

from models.llm_manager import LLMManager
from utils.html_generator import generate_chat_html
from ui.history_page import render_history_page
from ui.analysis_page import render_analysis_page
from ui.profile_page import render_profile_page

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="LLMä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)

# CSSã‚¹ã‚¿ã‚¤ãƒ«
st.markdown("""
<style>
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .chat-message.human {
        background-color: #e1ffc7;
        border-bottom-right-radius: 0;
        margin-left: 20%;
    }
    .chat-message.assistant {
        background-color: #f0f0f0;
        border-bottom-left-radius: 0;
        margin-right: 20%;
    }
    .chat-header {
        display: flex;
        justify-content: space-between;
        margin-bottom: 0.5rem;
    }
    .chat-role {
        font-weight: bold;
    }
    .chat-timestamp {
        font-size: 0.8rem;
        color: #888;
    }
    .chat-content {
        line-height: 1.5;
    }
    .stButton button {
        width: 100%;
    }
    .streaming-container {
        border: 1px solid #ddd;
        border-radius: 0.5rem;
        padding: 1rem;
        margin-bottom: 1rem;
        height: 300px;
        overflow-y: auto;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'llm_manager' not in st.session_state:
    st.session_state.llm_manager = LLMManager()
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []
if 'streaming_content' not in st.session_state:
    st.session_state.streaming_content = {"assistant": "", "human": ""}
if 'is_streaming' not in st.session_state:
    st.session_state.is_streaming = False
if 'current_page' not in st.session_state:
    st.session_state.current_page = "ä¼šè©±å®Ÿé¨“"

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.title("LLMä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
    
    # ãƒšãƒ¼ã‚¸é¸æŠ
    st.subheader("ãƒšãƒ¼ã‚¸")
    page = st.radio(
        "ãƒšãƒ¼ã‚¸ã‚’é¸æŠ",
        options=["ä¼šè©±å®Ÿé¨“", "ä¼šè©±å±¥æ­´", "ä¼šè©±åˆ†æ", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"],
        index=0,
        key="page_selection"
    )
    st.session_state.current_page = page
    
    if page == "ä¼šè©±å®Ÿé¨“":
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        assistant_model = st.selectbox(
            "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«",
            options=["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"],
            index=0,
        )
        human_model = st.selectbox(
            "äººé–“å½¹ãƒ¢ãƒ‡ãƒ«",
            options=["gpt-4o", "claude-3-opus", "claude-3-sonnet", "gemini-1.5-flash"],
            index=0,
        )
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
        st.subheader("ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        assistant_system_prompt = st.text_area(
            "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§æœ‰ç›Šãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
            height=150,
        )
        human_system_prompt = st.text_area(
            "äººé–“å½¹ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="ã‚ãªãŸã¯äººé–“ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã®ä¼šè©±ã§ã€è‡ªç„¶ãªè¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚è³ªå•ã¯å…·ä½“çš„ã«ã€ä¼šè©±ã¯è‡ªç„¶ã«é€²ã‚ã¦ãã ã•ã„ã€‚ãƒãƒ£ãƒƒãƒˆè¨€è‘‰ã§ã¯ãªãã€æ™®é€šã®è©±ã—è¨€è‘‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚",
            height=150,
        )
        
        # ä¼šè©±è¨­å®š
        st.subheader("ä¼šè©±è¨­å®š")
        num_turns = st.slider("ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°", min_value=1, max_value=20, value=5)
        use_streaming = st.checkbox("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨", value=True)
        
        # ä¿å­˜å½¢å¼
        st.subheader("ä¿å­˜å½¢å¼")
        save_json = st.checkbox("JSONã§ä¿å­˜", value=True)
        save_html = st.checkbox("HTMLã§ä¿å­˜", value=True)

# ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã«å¿œã˜ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º
if st.session_state.current_page == "ä¼šè©±å®Ÿé¨“":
    # ãƒ¡ã‚¤ãƒ³ç”»é¢
    st.title("LLMåŒå£«ã®ä¼šè©±å®Ÿé¨“")
    
    # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›
    initial_prompt = st.text_area(
        "åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆäººé–“å½¹ã®æœ€åˆã®ç™ºè¨€ï¼‰",
        value="ã“ã‚“ã«ã¡ã¯ï¼æœ€è¿‘ã€AIã«ã¤ã„ã¦èˆˆå‘³ã‚’æŒã¡å§‹ã‚ã¾ã—ãŸã€‚AIã®åŸºæœ¬çš„ãªä»•çµ„ã¿ã«ã¤ã„ã¦æ•™ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ",
        height=100,
    )
    
    # ä¼šè©±é–‹å§‹ãƒœã‚¿ãƒ³
    start_button = st.button("ä¼šè©±ã‚’é–‹å§‹")
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    if use_streaming:
        streaming_container = st.empty()
    
    # ä¼šè©±å±¥æ­´è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    conversation_container = st.container()
    
    # ä¼šè©±é–‹å§‹å‡¦ç†
    if start_button:
        # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®æ›´æ–°
        st.session_state.llm_manager.assistant_model = assistant_model
        st.session_state.llm_manager.human_model = human_model
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        def assistant_callback(chunk):
            st.session_state.streaming_content["assistant"] += chunk
            display_streaming()
            
        def human_callback(chunk):
            st.session_state.streaming_content["human"] += chunk
            display_streaming()
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºé–¢æ•°
        def display_streaming():
            with streaming_container.container():
                st.markdown("### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆä¸­...")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("#### ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
                    st.markdown(st.session_state.streaming_content["assistant"])
                with col2:
                    st.markdown("#### äººé–“å½¹")
                    st.markdown(st.session_state.streaming_content["human"])
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š
        stream_callbacks = None
        if use_streaming:
            st.session_state.is_streaming = True
            st.session_state.streaming_content = {"assistant": "", "human": ""}
            stream_callbacks = {
                "assistant": assistant_callback,
                "human": human_callback
            }
        
        # ä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        with st.spinner("LLMåŒå£«ã®ä¼šè©±ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã„ã¾ã™..."):
            conversation = st.session_state.llm_manager.simulate_conversation(
                initial_prompt=initial_prompt,
                assistant_system_prompt=assistant_system_prompt,
                human_system_prompt=human_system_prompt,
                num_turns=num_turns,
                stream=use_streaming,
                stream_callback=stream_callbacks
            )
            st.session_state.conversation_history = conversation
            st.session_state.is_streaming = False
        
        # ä¼šè©±å±¥æ­´ã®ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_files = []
        
        # ãƒ¡ã‚¿æƒ…å ±ã‚’è¿½åŠ 
        meta_info = {
            "meta": {
                "assistant_model": assistant_model,
                "human_model": human_model,
                "assistant_system_prompt": assistant_system_prompt,
                "human_system_prompt": human_system_prompt,
                "num_turns": num_turns,
                "timestamp": datetime.now().isoformat()
            }
        }
        conversation_with_meta = [meta_info] + conversation
        
        if save_json:
            json_file = f"conversations/conversation_{timestamp}.json"
            os.makedirs(os.path.dirname(json_file), exist_ok=True)
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(conversation_with_meta, f, ensure_ascii=False, indent=2)
            saved_files.append(f"JSONãƒ•ã‚¡ã‚¤ãƒ«: {json_file}")
            
        if save_html:
            html_file = f"conversations/conversation_{timestamp}.html"
            os.makedirs(os.path.dirname(html_file), exist_ok=True)
            html_content = generate_chat_html(conversation_with_meta, title="LLMä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
            with open(html_file, "w", encoding="utf-8") as f:
                f.write(html_content)
            saved_files.append(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«: {html_file}")
        
        if saved_files:
            st.success(f"ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ:\n" + "\n".join(saved_files))
    
    # ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
    with conversation_container:
        if st.session_state.conversation_history:
            st.subheader("ä¼šè©±å±¥æ­´")
            for message in st.session_state.conversation_history:
                role = message["role"]
                content = message["content"]
                timestamp = datetime.fromisoformat(message["timestamp"]).strftime("%Y-%m-%d %H:%M:%S")
                
                role_label = "äººé–“" if role == "human" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                
                st.markdown(f"""
                <div class="chat-message {role}">
                    <div class="chat-header">
                        <div class="chat-role">{role_label}</div>
                        <div class="chat-timestamp">{timestamp}</div>
                    </div>
                    <div class="chat-content">{content.replace(chr(10), '<br>')}</div>
                </div>
                """, unsafe_allow_html=True)

elif st.session_state.current_page == "ä¼šè©±å±¥æ­´":
    render_history_page()
    
elif st.session_state.current_page == "ä¼šè©±åˆ†æ":
    render_analysis_page()
    
elif st.session_state.current_page == "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«":
    render_profile_page()