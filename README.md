# LLM会話シミュレーター

LLM同士をチャットさせて、その会話履歴を保存・分析するための実験アプリケーションです。

## 最近の更新

- システムプロンプトを改善し、より自然な会話を実現
  - 短い発話と早いターンテイキングを促進するプロンプトに変更
  - 一方が主導する会話シナリオにも対応
- ストリーミング表示の安定性向上
- 会話分析機能の精度向上

## 機能

- Gemini 2.0 FlashをアシスタントとしたLLM同士の会話シミュレーション
- システムプロンプトをビジュアル的に編集可能
- ストリーミング機能によるリアルタイム会話表示
- 会話履歴のJSON/HTML形式での保存
- 会話履歴の閲覧と分析
- 構造化出力を活用した高度な会話分析
- 会話からのユーザープロファイル抽出機能
- 最大20ターンの長い会話シミュレーション

## 技術スタック

- Python 3.12+
- Streamlit: UIフレームワーク
- Google Generative AI (Gemini 2.0 Flash): アシスタント役LLM
- OpenAI API (GPT-4o): 人間役LLM
- Anthropic API (Claude 3): 人間役LLM
- 構造化出力による中間分析手法

## セットアップ

### 前提条件

- Python 3.12以上
- 各LLMのAPIキー（Google AI、OpenAI、Anthropic）

### インストール

1. リポジトリをクローン

```bash
git clone <repository-url>
cd llm-summarize
```

2. 仮想環境を作成して有効化

```bash
python -m venv .venv
source .venv/bin/activate  # Linuxの場合
# または
.venv\Scripts\activate  # Windowsの場合
```

3. 依存関係をインストール

```bash
pip install -e .
```

4. 環境変数を設定

`.env.example`ファイルを`.env`にコピーして、APIキーを設定します。

```bash
cp .env.example .env
```

`.env`ファイルを編集して、各APIキーを設定します。

```
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
```

## 使い方

### アプリケーションの起動

```bash
streamlit run src/app.py
```

ブラウザで`http://localhost:8501`を開くと、アプリケーションが表示されます。

### 会話実験

1. サイドバーで「会話実験」を選択
2. アシスタントモデル（Gemini 2.0 Flash推奨）と人間役モデルを選択
3. システムプロンプトを設定
4. 会話ターン数（最大20ターン）とストリーミングモードを設定
5. 初期プロンプトを入力
6. 「会話を開始」ボタンをクリック

### 会話履歴の閲覧

1. サイドバーで「会話履歴」を選択
2. HTML形式またはJSON形式のタブを選択
3. 閲覧したい会話履歴ファイルを選択

### 会話分析

1. サイドバーで「会話分析」を選択
2. 分析したい会話履歴ファイルを選択
3. 「会話を分析」ボタンをクリック
4. 分析結果がHTMLレポートとJSONで表示されます

### ユーザープロファイル抽出

1. サイドバーで「ユーザープロファイル」を選択
2. 「プロファイル抽出」タブを選択
3. 抽出したい会話履歴ファイルを選択
4. 「プロファイルを抽出」ボタンをクリック
5. 抽出されたプロファイルが表示されます

## 構造化出力による中間分析

このアプリケーションでは、Gemini 2.0 Flashの構造化出力機能を活用して、会話の中間分析を行っています。これにより、LLMの指示追従能力を向上させ、より高品質な分析結果を得ることができます。

中間分析では以下の情報を抽出します：

- 会話から抽出された主張
- 会話で扱われたトピック
- 会話の要約
- 感情分析
- 会話の自然さの分析

最終分析では、中間分析の結果を元に以下の情報を生成します：

- 会話のタイトル
- 会話の要約
- 重要なポイント
- 主要なトピック
- 人間役の分析（自然さ、強み、弱み、改善提案）
- アシスタントの分析（役立ち度、正確さ、強み、弱み）
- 会話全体の質の評価

### ユーザープロファイル抽出

会話履歴からユーザー（人間役）に関する情報を抽出し、次回の会話に活用するための機能です。抽出される情報は以下の3つのカテゴリに分類されます：

1. **プロフィール情報**：生年月日、名前、職業、家族構成などの基本情報
2. **コンテキスト情報**：趣味、関心事、過去の経験などの一般的な記憶。複数回の会話がある場合は日時も記録
3. **次回の会話トピック**：次回の会話で聞くべき質問や話題（「前回こういう話をしていたけど、その後どうなった？」など）

抽出されたプロファイルはJSON形式とHTML形式で保存され、いつでも閲覧できます。これにより、LLMが人間らしい会話の継続性を持つことができます。

## Gemini 2.0 Flashについて

Gemini 2.0 Flashは、Google AIの最新モデルで、高速かつ高品質な応答が特徴です。このアプリケーションでは、Gemini 2.0 Flashを優先的に使用し、エラーが発生した場合はGemini 1.5 Proにフォールバックする仕組みを実装しています。

Gemini 2.0 Flashを使用するには、最新のGoogle AI APIキーが必要です。また、APIの使用量制限にご注意ください。

## ライセンス

MIT

## システムプロンプト設計

このアプリケーションでは、より自然な会話を実現するために、以下のようなシステムプロンプトを採用しています：

### アシスタント用システムプロンプト
```
あなたは親切で役立つAIアシスタントです。普段友達と話すように、あの…ええと、少しどもりながら自然な会話をする感じで、質問に対して分かりやすく答えてください。専門的な内容も、固い表現を避け、軽い口調で説明します。ASRで録音されたような、多少のフィラーや言い間違いがあっても構わない、リアルな会話感を大事にしてください。会話は、各発話が短く区切られ、早めにターンテイキングが発生するようにしてください。
```

### 人間役用システムプロンプト
```
あなたはおしゃべりでフレンドリーな人間です。普段の会話では、時々『えーっと』や『あのー』などのフィラーが入ることもあり、自然な話し言葉で話します。ASRで変換された、少し曖昧で省略が多い会話文でも構いません。会話は、発話が短く、息継ぎやターンテイキングが早く起こるように設計してください。場合によっては、一方が優位なスピーカーとなり続け、もう一方が聞く一方になるシナリオも想定してください。
```

これらのプロンプトにより、より人間らしい自然な会話が実現できます。
